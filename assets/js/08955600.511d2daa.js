"use strict";(self.webpackChunkb_2_dvl_docs_site=self.webpackChunkb_2_dvl_docs_site||[]).push([[4676],{903:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>a,contentTitle:()=>l,default:()=>h,frontMatter:()=>s,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"references/inference-config","title":"Inference Configurations","description":"Inference configurations of open-loop and closed-loop methods.","source":"@site/docs/references/inference-config.md","sourceDirName":"references","slug":"/references/inference-config","permalink":"/Bench2Drive-VL/docs/next/references/inference-config","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Graph Configurations","permalink":"/Bench2Drive-VL/docs/next/references/graph-config"},"next":{"title":"Evaluation Configurations","permalink":"/Bench2Drive-VL/docs/next/references/eval-config"}}');var o=t(4848),r=t(8453);const s={sidebar_position:3},l="Inference Configurations",a={},c=[{value:"Closed-Loop inference",id:"closed-loop-inference",level:2},{value:"Example",id:"example",level:3},{value:"Fields",id:"fields",level:3},{value:"TASK_CONFIGS",id:"task_configs",level:4},{value:"INFERENCE_BASICS",id:"inference_basics",level:4},{value:"CHAIN",id:"chain",level:4},{value:"Other Fields",id:"other-fields",level:4},{value:"Open-Loop inference",id:"open-loop-inference",level:2},{value:"Example",id:"example-1",level:3},{value:"Fields",id:"fields-1",level:3},{value:"TASK_CONFIGS",id:"task_configs-1",level:4},{value:"INFERENCE_BASICS",id:"inference_basics-1",level:4},{value:"CHAIN",id:"chain-1",level:4},{value:"Subset File",id:"subset-file",level:3},{value:"Checkpoint File",id:"checkpoint-file",level:3},{value:"Entry Exit File",id:"entry-exit-file",level:3},{value:"Appendix File",id:"appendix-file",level:3}];function d(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"inference-configurations",children:"Inference Configurations"})}),"\n",(0,o.jsx)(n.p,{children:"Inference configurations of open-loop and closed-loop methods."}),"\n",(0,o.jsx)(n.h2,{id:"closed-loop-inference",children:"Closed-Loop inference"}),"\n",(0,o.jsx)(n.p,{children:"In closed-loop inference, main module (with CARLA) shares the same config file with VLM module."}),"\n",(0,o.jsx)(n.h3,{id:"example",children:"Example"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-json",children:'{\n    "TASK_CONFIGS": {\n        "FRAME_PER_SEC": 10\n    },\n    "INFERENCE_BASICS": {\n        "INPUT_WINDOW": 1, // frame count of given image input\n        "CONVERSATION_WINDOW": 1, // not used anymore, to be removed\n        "USE_ALL_CAMERAS": false, // true if use all cameras as input\n        "USE_BEV": false, // true if use bev as input\n        "NO_HISTORY_MODE": false // do not inherit context of previous VQAs\n    },\n    "CHAIN": { // for inference\n        "NODE": [19, 15, 7, 24, 13, 47, 8, 43, 50],\n        "EDGE": { // "pred": succ\n            "19": [24, 13, 8],\n            "15": [7, 8],\n            "7": [8],\n            "24": [13, 47],\n            "13": [47, 8, 43],\n            "47": [8],\n            "8": [43],\n            "43": [50],\n            "50": []\n        },\n        "INHERIT": { // inherit context from last frame\n            "19": [43, 7],\n            "15": [7]\n        },\n        "USE_GT": [24] // questions which use ground truth as answer\n    },\n    "CONTROL_RATE": 2.0, // intervene frequency of vlm\n    "MODEL_NAME": "api", // model name, please check out supported models\n    "MODEL_PATH": "../model_zoo/your_model", // model path\n    "GPU_ID": 0, // the gpu model runs on\n    "PORT": 7023, // web port\n    "IN_CARLA": true,\n    "USE_BASE64": true, // if false, local path is used for transmitting images\n    "NO_PERC_INFO": false // do not pass extra perception info to vlm via prompt\n}\n'})}),"\n",(0,o.jsx)(n.h3,{id:"fields",children:"Fields"}),"\n",(0,o.jsx)(n.h4,{id:"task_configs",children:"TASK_CONFIGS"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"FRAME_PER_SEC"})," (type: ",(0,o.jsx)(n.code,{children:"int"}),"): The sampling rate of the sensors."]}),"\n"]}),"\n",(0,o.jsx)(n.h4,{id:"inference_basics",children:"INFERENCE_BASICS"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"INPUT_WINDOW"})," (type: ",(0,o.jsx)(n.code,{children:"int"}),"): Frame count of given visual input."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"CONVERSATION_WINDOW"})," (type: ",(0,o.jsx)(n.code,{children:"int"}),"): Not used anymore, to be removed. Used to determine context length."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"USE_ALL_CAMERAS"})," (type: ",(0,o.jsx)(n.code,{children:"bool"}),"): True if use all 6 cameras as input."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"USE_BEV"})," (type: ",(0,o.jsx)(n.code,{children:"bool"}),"): True if use BEV image as input."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"NO_HISTORY_MODE"})," (type: ",(0,o.jsx)(n.code,{children:"bool"}),"): True if do not inherit context of previous VQAs."]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.h4,{id:"chain",children:"CHAIN"}),"\n",(0,o.jsxs)(n.p,{children:["Please refer to ",(0,o.jsx)(n.a,{href:"/Bench2Drive-VL/docs/next/references/graph-config",children:"graph configs"}),"."]}),"\n",(0,o.jsx)(n.h4,{id:"other-fields",children:"Other Fields"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"CONTROL_RATE"})," (type: ",(0,o.jsx)(n.code,{children:"float"}),"): Intervene frequency of VLM"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"MODEL_NAME"})," (type: ",(0,o.jsx)(n.code,{children:"str"}),"): Model name, please check out supported models in ",(0,o.jsx)(n.code,{children:"models/register.py"}),", or refer to ",(0,o.jsx)(n.a,{href:"/Bench2Drive-VL/docs/next/references/adapt-vlm",children:"VLM adapting tutorial"}),"."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"MODEL_PATH"})," (type: ",(0,o.jsx)(n.code,{children:"str"}),"): Path to the folder of your model downloaded from huggingface."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"GPU_ID"})," (type: ",(0,o.jsx)(n.code,{children:"int"}),"): The gpu your VLM runs on."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"PORT"})," (type: ",(0,o.jsx)(n.code,{children:"int"}),"): The web port which used to connect CARLA and VLM."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"IN_CARLA"})," (type: ",(0,o.jsx)(n.code,{children:"bool"}),"): An environment variable which ",(0,o.jsx)(n.strong,{children:"must set to true"})," if doing closed-loop evaluation."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"USE_BASE64"})," (type: ",(0,o.jsx)(n.code,{children:"bool"}),"): If true, base64 is used for transmitting images. Otherwise, local path is used."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"NO_PERC_INFO"})," (type: ",(0,o.jsx)(n.code,{children:"bool"}),"): If true, extra perception info won't be passed to the VLM via text prompt."]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.admonition,{title:"Remote Situation",type:"tip",children:(0,o.jsxs)(n.p,{children:["When CARLA and the VLM are running on separate machines, you may enable ",(0,o.jsx)(n.code,{children:"USE_BASE64"})," and apply port forwarding to redirect the VLM's port to the local environment."]})}),"\n",(0,o.jsx)(n.admonition,{title:"early-stop",type:"info",children:(0,o.jsxs)(n.p,{children:["When getting ",(0,o.jsx)(n.a,{href:"/Bench2Drive-VL/docs/next/references/baselines",children:"baseline data"}),", we used a 80s early-stop to avoid wasting time on failed scenarios. This is controlled by the ",(0,o.jsx)(n.code,{children:"EARLY_STOP"})," environment variable in ",(0,o.jsx)(n.a,{href:"/Bench2Drive-VL/docs/next/tutorial/closed-loop-inference#write-a-start-up-script",children:"start up script"}),". If this variable is not given, early-stop will be disabled."]})}),"\n",(0,o.jsx)(n.h2,{id:"open-loop-inference",children:"Open-Loop inference"}),"\n",(0,o.jsx)(n.h3,{id:"example-1",children:"Example"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-json",children:'{\n    "TASK_CONFIGS": {\n        "INFER_SUBSET": false,\n        "USE_CHECKPOINT": true,\n        "SUBSET_FILE": "./infer_configs/subset.txt",\n        "CHECKPOINT_FILE": "./infer_configs/finished_scenarios.txt",\n        "ENTRY_EXIT_FILE": "./infer_configs/entry_exits.json",\n        "FRAME_PER_SEC": 10\n    },\n    "INFERENCE_BASICS": {\n        "INPUT_WINDOW": 1,\n        "CONVERSATION_WINDOW": 2,\n        "USE_ALL_CAMERAS": true,\n        "NO_HISTORY_MODE": false,\n        "APPEND_QUESTION": true,\n        "APPENDIX_FILE": "./infer_configs/append_questions.json"\n    },\n    "CHAIN": {\n        "NODE": [43, 50],\n        "EDGE": {\n            "43": [50],\n            "50": []\n        },\n        "INHERIT": {\n            "19": [43, 7],\n            "15": [7]\n        },\n        "USE_GT": []\n    }\n}\n'})}),"\n",(0,o.jsx)(n.h3,{id:"fields-1",children:"Fields"}),"\n",(0,o.jsx)(n.h4,{id:"task_configs-1",children:"TASK_CONFIGS"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"INFER_SUBSET"})," (type: ",(0,o.jsx)(n.code,{children:"bool"}),"): Whether inference a subset of given dataset or not."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"USE_CHECKPOINT"})," (type: ",(0,o.jsx)(n.code,{children:"bool"}),"): Whether use a checkpoint file to record the process of inference, so that B2DVL only inference scenarios which are not in the checkpoint file."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"SUBSET_FILE"})," (type: ",(0,o.jsx)(n.code,{children:"str"}),"): Path to the subset file. You can leave blank if not used."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"CHECKPOINT_FILE"})," (type: ",(0,o.jsx)(n.code,{children:"str"}),"): Path to the checkpoint file. You can leave blank if not used."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"ENTRY_EXIT_FILE"})," (type: ",(0,o.jsx)(n.code,{children:"str"}),"): Path to the entry exit file, this is the file which specifies entry and exit point of certain scenarios."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"FRAME_PER_SEC"})," (type: ",(0,o.jsx)(n.code,{children:"int"}),"): The sampling rate of the sensors."]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.h4,{id:"inference_basics-1",children:"INFERENCE_BASICS"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"INPUT_WINDOW"})," (type: ",(0,o.jsx)(n.code,{children:"int"}),"): Frame count of given visual input."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"CONVERSATION_WINDOW"})," (type: ",(0,o.jsx)(n.code,{children:"int"}),"): Not used anymore, to be removed. Used to determine context length."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"USE_ALL_CAMERAS"})," (type: ",(0,o.jsx)(n.code,{children:"bool"}),"): True if use all 6 cameras as input."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"USE_BEV"})," (type: ",(0,o.jsx)(n.code,{children:"bool"}),"): True if use BEV image as input."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"NO_HISTORY_MODE"})," (type: ",(0,o.jsx)(n.code,{children:"bool"}),"): True if do not inherit context of previous VQAs."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"APPEND_QUESTION"})," (type: ",(0,o.jsx)(n.code,{children:"bool"}),"): True if using appended questions."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"APPENDIX_FILE"})," (type: ",(0,o.jsx)(n.code,{children:"str"}),"): Path to appended question file, which contains extra questions you defined which is not included in supported questions."]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.h4,{id:"chain-1",children:"CHAIN"}),"\n",(0,o.jsxs)(n.p,{children:["Please refer to ",(0,o.jsx)(n.a,{href:"/Bench2Drive-VL/docs/next/references/graph-config",children:"graph configs"}),"."]}),"\n",(0,o.jsx)(n.h3,{id:"subset-file",children:"Subset File"}),"\n",(0,o.jsx)(n.p,{children:"A file simply consists of scenario folders' names. If subset file is used, B2DVL will only infer scenarios which are mentioned in this file."}),"\n",(0,o.jsx)(n.p,{children:"An example:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-txt",children:"AccidentTwoWays_Town12_Route1102_Weather10\nAccidentTwoWays_Town12_Route1103_Weather11\nAccident_Town03_Route101_Weather23\nAccident_Town03_Route102_Weather20\nBlockedIntersection_Town03_Route134_Weather3\nBlockedIntersection_Town03_Route135_Weather5\nConstructionObstacleTwoWays_Town12_Route1080_Weather14\nConstructionObstacleTwoWays_Town12_Route1083_Weather9\nConstructionObstacle_Town03_Route60_Weather8\nConstructionObstacle_Town03_Route61_Weather9\nControlLoss_Town04_Route169_Weather13\nControlLoss_Town04_Route170_Weather14\nCrossingBicycleFlow_Town12_Route1011_Weather23\nCrossingBicycleFlow_Town12_Route1012_Weather23\nDynamicObjectCrossing_Town01_Route1_Weather1\nDynamicObjectCrossing_Town01_Route2_Weather2\nEnterActorFlow_Town03_Route132_Weather2\nEnterActorFlow_Town04_Route192_Weather10\nHardBreakRoute_Town01_Route30_Weather3\nHardBreakRoute_Town01_Route31_Weather5\nHazardAtSideLaneTwoWays_Town12_Route1128_Weather10\nHazardAtSideLaneTwoWays_Town12_Route1129_Weather11\nHazardAtSideLane_Town03_Route105_Weather22\nHazardAtSideLane_Town03_Route106_Weather23\nHighwayCutIn_Town06_Route298_Weather20\nHighwayCutIn_Town06_Route299_Weather13\nHighwayExit_Town06_Route291_Weather5\nHighwayExit_Town06_Route292_Weather14\nInterurbanActorFlow_Town06_Route294_Weather8\nInterurbanActorFlow_Town06_Route314_Weather2\nInterurbanAdvancedActorFlow_Town06_Route301_Weather15\nInterurbanAdvancedActorFlow_Town06_Route302_Weather21\nInvadingTurn_Town02_Route95_Weather9\nInvadingTurn_Town02_Route99_Weather21\nLaneChange_Town06_Route277_Weather9\nLaneChange_Town06_Route307_Weather21\nMergerIntoSlowTrafficV2_Town12_Route1009_Weather21\nMergerIntoSlowTrafficV2_Town12_Route1010_Weather22\nMergerIntoSlowTraffic_Town06_Route317_Weather5\nMergerIntoSlowTraffic_Town12_Route1003_Weather8\nNonSignalizedJunctionLeftTurnEnterFlow_Town12_Route1022_Weather8\nNonSignalizedJunctionLeftTurnEnterFlow_Town12_Route1035_Weather21\nNonSignalizedJunctionLeftTurn_Town03_Route122_Weather26\nNonSignalizedJunctionLeftTurn_Town03_Route123_Weather26\nNonSignalizedJunctionRightTurn_Town03_Route126_Weather18\nNonSignalizedJunctionRightTurn_Town04_Route184_Weather2\nOppositeVehicleRunningRedLight_Town03_Route119_Weather12\nOppositeVehicleRunningRedLight_Town03_Route120_Weather8\nOppositeVehicleTakingPriority_Town03_Route128_Weather23\nOppositeVehicleTakingPriority_Town03_Route155_Weather25\nParkedObstacleTwoWays_Town12_Route1158_Weather14\nParkedObstacleTwoWays_Town12_Route1159_Weather23\nParkedObstacle_Town03_Route103_Weather25\nParkedObstacle_Town03_Route147_Weather0\nParkingCrossingPedestrian_Town12_Route758_Weather3\nParkingCrossingPedestrian_Town12_Route759_Weather5\nParkingCutIn_Town12_Route1300_Weather13\nParkingCutIn_Town12_Route1301_Weather14\nParkingExit_Town12_Route1305_Weather18\nParkingExit_Town12_Route1307_Weather20\nPedestrianCrossing_Town12_Route1013_Weather25\nPedestrianCrossing_Town12_Route1014_Weather0\nSignalizedJunctionLeftTurnEnterFlow_Town12_Route1019_Weather5\nSignalizedJunctionLeftTurnEnterFlow_Town12_Route1020_Weather6\nSignalizedJunctionLeftTurn_Town03_Route113_Weather26\nSignalizedJunctionLeftTurn_Town03_Route114_Weather6\nSignalizedJunctionRightTurn_Town03_Route118_Weather14\nSignalizedJunctionRightTurn_Town03_Route151_Weather2\nStaticCutIn_Town03_Route109_Weather1\nStaticCutIn_Town03_Route110_Weather6\nTJunction_Town01_Route90_Weather12\nTJunction_Town01_Route91_Weather13\nVanillaNonSignalizedTurnEncounterStopsign_Town03_Route143_Weather13\nVanillaNonSignalizedTurnEncounterStopsign_Town03_Route144_Weather14\nVanillaSignalizedTurnEncounterGreenLight_Town03_Route137_Weather7\nVanillaSignalizedTurnEncounterGreenLight_Town03_Route139_Weather9\nVanillaSignalizedTurnEncounterRedLight_Town03_Route140_Weather10\nVanillaSignalizedTurnEncounterRedLight_Town03_Route141_Weather11\nVehicleOpensDoorTwoWays_Town12_Route1196_Weather0\nVehicleOpensDoorTwoWays_Town12_Route1197_Weather1\nVehicleTurningRoutePedestrian_Town12_Route1027_Weather13\nVehicleTurningRoutePedestrian_Town12_Route1040_Weather0\nVehicleTurningRoute_Town12_Route1026_Weather12\nVehicleTurningRoute_Town12_Route822_Weather18\nYieldToEmergencyVehicle_Town03_Route148_Weather18\nYieldToEmergencyVehicle_Town04_Route165_Weather7\n"})}),"\n",(0,o.jsx)(n.p,{children:"This example consists of exactly two route scenarios in each scenario class."}),"\n",(0,o.jsx)(n.h3,{id:"checkpoint-file",children:"Checkpoint File"}),"\n",(0,o.jsx)(n.p,{children:"Checkpoint file shares the same grammar as subset file. For each line, if this line is a substring of current scenario's folder path, this scenario is skipped."}),"\n",(0,o.jsx)(n.h3,{id:"entry-exit-file",children:"Entry Exit File"}),"\n",(0,o.jsx)(n.p,{children:"In some scenarios, you might not want the VLM to infer all of its frames. You can use an entry exit file to configure a interval. For example:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-json",children:'{\n    "Accident_Town03_Route101_Weather23": {\n        "entry": 40,\n        "exit": 120\n    },\n    "YieldToEmergencyVehicle_Town03_Route148_Weather18": {\n        "entry": 5,\n        "exit": 150\n    },\n    "ConstructionObstacleTwoWays_Town12_Route1080_Weather14": {\n        "entry": 15,\n        "exit": 140\n    },\n    "ConstructionObstacle_Town03_Route60_Weather8": {\n        "entry": 15,\n        "exit": 150\n    },\n    "CrossingBicycleFlow_Town12_Route1062_Weather22": {\n        "entry": 330,\n        "exit": 370\n    },\n    "HardBreakRoute_Town01_Route30_Weather3": {\n        "entry": 10,\n        "exit": 80\n    },\n    "ParkedObstacleTwoWays_Town12_Route1158_Weather14": {\n        "entry": 20,\n        "exit": 245\n    }\n}\n'})}),"\n",(0,o.jsxs)(n.p,{children:["This file specifies the starting point and the endding point of 7 scenarios. When infering them, only frames within ",(0,o.jsx)(n.code,{children:"[entry, exit)"})," is infered. For scenarios which are not mentioned, all frames are infered."]}),"\n",(0,o.jsx)(n.h3,{id:"appendix-file",children:"Appendix File"}),"\n",(0,o.jsx)(n.p,{children:"If you want to add extra questions for VLM to answer, you can write an appendix file to define more questions. But remember to pick unused qid. Since customized questions are not supported by DriveCommenter, they can not be evaluated by our evaluation module. You have to do some extra work to evaluate them."}),"\n",(0,o.jsx)(n.p,{children:"An example:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-json",children:'[\n    {\n        "Q": "According to the current situation, what should the ego vehicle do?",\n        "A": "To be simulated",\n        "C": null,\n        "qid": 52,\n        "con_up": [\n            [\n                -1,\n                -1\n            ]\n        ],\n        "con_down": [\n            [\n                -1,\n                -1\n            ]\n        ],\n        "cluster": -1,\n        "layer": -1,\n        "object_tags": [\n        ]\n    },\n    {\n        "Q": "According to the current situation, which direction should the ego vehicle go? A) Go straight along the current lane. B) Change to the left lane. C) Change to the right lane. D) Steer left. E) Steer right. If the answer is in D or E, try to provide the precise angle for steering.",\n        "A": "To be simulated",\n        "C": null,\n        "qid": 53,\n        "con_up": [\n            [\n                -1,\n                -1\n            ]\n        ],\n        "con_down": [\n            [\n                -1,\n                -1\n            ]\n        ],\n        "cluster": -1,\n        "layer": -1,\n        "object_tags": [\n        ]\n    },\n    {\n        "Q": "According to the current situation, at what speed should the ego vehicle drive? A) Remain current speed. B) Accelerate. C) Decelerate. D) Stop. After select these options, try to provide precise target speed.",\n        "A": "To be simulated",\n        "C": null,\n        "qid": 54,\n        "con_up": [\n            [\n                -1,\n                -1\n            ]\n        ],\n        "con_down": [\n            [\n                -1,\n                -1\n            ]\n        ],\n        "cluster": -1,\n        "layer": -1,\n        "object_tags": [\n        ]\n    }\n]\n'})})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>s,x:()=>l});var i=t(6540);const o={},r=i.createContext(o);function s(e){const n=i.useContext(r);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:s(e.components),i.createElement(r.Provider,{value:n},e.children)}}}]);